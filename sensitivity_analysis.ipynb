{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcdFRp1AVf7iqW1G6VFjhd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AcornSJ/kessler-neural-ode/blob/main/sensitivity_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install diffrax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLVEcrxeTUZ8",
        "outputId": "84b87ab9-4339-4d3f-bb78-787c2913bf4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffrax\n",
            "  Downloading diffrax-0.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting equinox>=0.11.10 (from diffrax)\n",
            "  Downloading equinox-0.13.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: jax>=0.4.38 in /usr/local/lib/python3.12/dist-packages (from diffrax) (0.7.2)\n",
            "Collecting jaxtyping>=0.2.24 (from diffrax)\n",
            "  Downloading jaxtyping-0.3.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting lineax>=0.0.5 (from diffrax)\n",
            "  Downloading lineax-0.0.8-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting optimistix>=0.0.10 (from diffrax)\n",
            "  Downloading optimistix-0.0.11-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from diffrax) (4.15.0)\n",
            "Collecting wadler-lindig>=0.1.1 (from diffrax)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jaxlib<=0.7.2,>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.38->diffrax) (0.7.2)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.38->diffrax) (0.5.4)\n",
            "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.38->diffrax) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.38->diffrax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.38->diffrax) (1.16.3)\n",
            "Downloading diffrax-0.7.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.2/193.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading equinox-0.13.2-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.3.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lineax-0.0.8-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimistix-0.0.11-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: wadler-lindig, jaxtyping, equinox, lineax, optimistix, diffrax\n",
            "Successfully installed diffrax-0.7.0 equinox-0.13.2 jaxtyping-0.3.3 lineax-0.0.8 optimistix-0.0.11 wadler-lindig-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_49f_LMTMpB",
        "outputId": "352058e9-e3c1-4fc7-8375-cfbe36005b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Simulation Settings ---\n",
            "Time range: 0 to 100.0\n",
            "Collapse Threshold (D < x): 15000\n",
            "\n",
            "--- Training Neural ODE (Quick Check) ---\n",
            "Step 0, Loss: 2450.562012\n",
            "Step 100, Loss: 2.019602\n",
            "Step 200, Loss: 0.161518\n"
          ]
        }
      ],
      "source": [
        "import jax.random as jr\n",
        "import jax.numpy as jnp\n",
        "import equinox as eqx\n",
        "import optax\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import diffrax\n",
        "import jax\n",
        "import jax.nn as jnn\n",
        "\n",
        "class Func(eqx.Module):\n",
        "    out_scale: jax.Array\n",
        "    mlp: eqx.nn.MLP\n",
        "\n",
        "    def __init__(self, data_size, width_size, depth, *, key, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.out_scale = jnp.array(1.0)\n",
        "        self.mlp = eqx.nn.MLP(\n",
        "            in_size=data_size,\n",
        "            out_size=data_size,\n",
        "            width_size=width_size,\n",
        "            depth=depth,\n",
        "            activation=jnn.softplus,\n",
        "            final_activation=jax.nn.tanh,\n",
        "            key=key,\n",
        "        )\n",
        "\n",
        "    def __call__(self, t, y, args):\n",
        "        y_processed = jnp.atleast_1d(y)\n",
        "        return self.out_scale * self.mlp(y_processed)\n",
        "\n",
        "class NeuralODE(eqx.Module):\n",
        "    func: Func\n",
        "\n",
        "    def __init__(self, data_size, width_size, depth, *, key, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.func = Func(data_size, width_size, depth, key=key)\n",
        "\n",
        "    def __call__(self, ts, y0):\n",
        "        solution = diffrax.diffeqsolve(\n",
        "            diffrax.ODETerm(self.func),\n",
        "            diffrax.Tsit5(),\n",
        "            t0=ts[0],\n",
        "            t1=ts[-1],\n",
        "            dt0=ts[1] - ts[0],\n",
        "            y0=y0,\n",
        "            stepsize_controller=diffrax.PIDController(rtol=1e-3, atol=1e-6),\n",
        "            saveat=diffrax.SaveAt(ts=ts),\n",
        "        )\n",
        "        return solution.ys\n",
        "\n",
        "def _get_data(ts, lambda_t_val, alpha, mu, k, beta, *, key):\n",
        "    y0 = jr.uniform(key, (2,), minval=20000, maxval=30000)\n",
        "\n",
        "    def lambda_t(t):\n",
        "        return lambda_t_val\n",
        "\n",
        "    def f(t, y, args):\n",
        "        return jnp.stack(\n",
        "            [lambda_t(t) - alpha * y[0] * y[1] - mu * y[0],\n",
        "             k * alpha * y[0] * y[1] - beta * y[1]], axis=-1)\n",
        "\n",
        "    solver = diffrax.Tsit5()\n",
        "    dt0 = 0.1\n",
        "    saveat = diffrax.SaveAt(ts=ts)\n",
        "    sol = diffrax.diffeqsolve(\n",
        "        diffrax.ODETerm(f), solver, ts[0], ts[-1], dt0, y0, saveat=saveat\n",
        "    )\n",
        "    return sol.ys\n",
        "\n",
        "def get_data(dataset_size, lambda_t_val, alpha, mu, k, beta, ts, *, key):\n",
        "    key = jr.split(key, dataset_size)\n",
        "    vmapped_func = jax.vmap(lambda key: _get_data(ts, lambda_t_val, alpha, mu, k, beta, key=key))\n",
        "    ys = vmapped_func(key)\n",
        "    return ys\n",
        "\n",
        "def dataloader(arrays, batch_size, *, key):\n",
        "    dataset_size = arrays[0].shape[0]\n",
        "    indices = jnp.arange(dataset_size)\n",
        "    while True:\n",
        "        perm = jr.permutation(key, indices)\n",
        "        (key,) = jr.split(key, 1)\n",
        "        start = 0\n",
        "        end = batch_size\n",
        "        while end < dataset_size:\n",
        "            batch_perm = perm[start:end]\n",
        "            yield tuple(array[batch_perm] for array in arrays)\n",
        "            start = end\n",
        "            end = start + batch_size\n",
        "\n",
        "def calculate_time_to_collapse(ts, ys, collapse_threshold):\n",
        "    current_debris = ys[0, :, 1]\n",
        "    is_collapsed = current_debris > collapse_threshold\n",
        "    has_collapsed = jnp.any(is_collapsed)\n",
        "    first_collapse_idx = jnp.argmax(is_collapsed)\n",
        "    return jax.lax.cond(\n",
        "        has_collapsed,\n",
        "        lambda: ts[first_collapse_idx],\n",
        "        lambda: ts[-1])\n"
        "\n",
        "def sensitivity_analysis(param_name, param_values, ts, initial_params, collapse_threshold):\n",
        "    results = []\n",
        "    p = initial_params.copy()\n",
        "    analysis_key = jr.PRNGKey(999)\n",
        "    for val in param_values:\n",
        "        p[param_name] = val\n",
        "        ys = _get_data(\n",
        "            ts=ts,\n",
        "            lambda_t_val=p['lambda_t_val'],\n",
        "            alpha=p['alpha'],\n",
        "            mu=p['mu'],\n",
        "            k=p['k'],\n",
        "            beta=p['beta'],\n",
        "            key=analysis_key\n",
        "        )\n",
        "        time_to_collapse = calculate_time_to_collapse(ts, jnp.expand_dims(ys, axis=0), collapse_threshold)\n",
        "        results.append(time_to_collapse)\n",
        "    return jnp.array(results)\n",
        "\n",
        "def main_dramatic_analysis(\n",
        "    dataset_size=64,\n",
        "    batch_size=32,\n",
        "    lr=1e-3,\n",
        "    steps_strategy=(500, 500),\n",
        "    length_strategy=(0.5, 1),\n",
        "    width_size=64,\n",
        "    depth=2,\n",
        "    seed=5678,\n",
        "):\n",
        "    key = jr.PRNGKey(seed)\n",
        "    data_key, model_key, loader_key = jr.split(key, 3)\n",
        "    ts = jnp.linspace(0, 100, 200)\n",
        "    collapse_threshold = 15000\n",
        "    initial_params = {\n",
        "        'alpha': 4e-10,\n",
        "        'mu': 0.05,\n",
        "        'k': 2000.0,\n",
        "        'beta': 0.015,\n",
        "        'lambda_t_val': 1500,\n",
        "    }\n",
        "\n",
        "    print(f\"--- Simulation Settings ---\")\n",
        "    print(f\"Time range: 0 to {ts[-1]}\")\n",
        "    print(f\"Collapse Threshold (D < x): {collapse_threshold}\")\n",
        "\n",
        "    dummy_ys = _get_data(ts, **initial_params, key=data_key)\n",
        "    data_size = dummy_ys.shape[-1]\n",
        "    length_size = ts.shape[0]\n",
        "    print(\"\\n--- Training Neural ODE (Quick Check) ---\")\n",
        "\n",
        "    ys = get_data(dataset_size, **initial_params, ts=ts, key=data_key)\n",
        "\n",
        "\n",
        "    min_ys, max_ys = jnp.min(ys), jnp.max(ys)\n",
        "    ys_norm = (ys - min_ys) / (max_ys - min_ys)\n",
        "\n",
        "    model = NeuralODE(data_size, width_size, depth, key=model_key)\n",
        "    optim = optax.adam(lr)\n",
        "    opt_state = optim.init(eqx.filter(model, eqx.is_inexact_array))\n",
        "\n",
        "    @eqx.filter_value_and_grad\n",
        "    def grad_loss(model, ti, yi):\n",
        "        y_pred = jax.vmap(model, in_axes=(None, 0))(ti, yi[:, 0])\n",
        "        return jnp.mean((yi - y_pred) ** 2)\n",
        "\n",
        "    @eqx.filter_jit\n",
        "    def make_step(ti, yi, model, opt_state):\n",
        "        loss, grads = grad_loss(model, ti, yi)\n",
        "        updates, opt_state = optim.update(grads, opt_state)\n",
        "        model = eqx.apply_updates(model, updates)\n",
        "        return loss, model, opt_state\n",
        "\n",
        "\n",
        "    for i in range(500):\n",
        "        yi = ys_norm[:batch_size]\n",
        "        loss, model, opt_state = make_step(ts, yi, model, opt_state)\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Step {i}, Loss: {loss:.6f}\")\n",
        "\n",
        "\n",
        "    print(\"\\n--- Sensitivity Analysis (Generating Plots) ---\")\n",
        "\n",
        "\n",
        "    analysis_params = {\n",
        "        'lambda_t_val': jnp.linspace(0, 5000, 30),\n",
        "\n",
        "        'alpha': jnp.linspace(1e-10, 20e-10, 30),\n",
        "\n",
        "        'mu': jnp.linspace(0.01, 0.2, 30),\n",
        "\n",
        "        'k': jnp.linspace(100, 5000, 30),\n",
        "\n",
        "        'beta': jnp.linspace(0.001, 0.1, 30),\n",
        "    }\n",
        "\n",
        "    sensitivity_results = {}\n",
        "\n",
        "    for param_name, param_values in analysis_params.items():\n",
        "        print(f\"Analyzing {param_name}...\")\n",
        "        collapse_times = sensitivity_analysis(\n",
        "            param_name,\n",
        "            param_values,\n",
        "            ts,\n",
        "            initial_params,\n",
        "            collapse_threshold\n",
        "        )\n",
        "        sensitivity_results[param_name] = (param_values, collapse_times)\n",
        "\n",
        "    n_params = len(analysis_params)\n",
        "    fig, axes = plt.subplots(1, n_params, figsize=(4 * n_params, 5), constrained_layout=True)\n",
        "\n",
        "    fig.suptitle(f'Sensitivity: Time to Reach Density < {collapse_threshold}\\n(Max Time: {ts[-1]})', fontsize=16)\n",
        "\n",
        "    for i, (param_name, (values, times)) in enumerate(sensitivity_results.items()):\n",
        "        ax = axes[i]\n",
        "        max_time = ts[-1]\n",
        "\n",
        "        collapsed = times < max_time\n",
        "\n",
        "        ax.plot(values, times, color='gray', linestyle='--', alpha=0.5)\n",
        "        if jnp.any(collapsed):\n",
        "            ax.scatter(values[collapsed], times[collapsed], color='red', label='Collapsed')\n",
        "        if jnp.any(~collapsed):\n",
        "            ax.scatter(values[~collapsed], times[~collapsed], color='blue', marker='s', label='Safe')\n",
        "\n",
        "        ax.axhline(max_time, color='green', linestyle=':', label='Max Time')\n",
        "        ax.set_xlabel(f'{param_name}')\n",
        "        ax.set_ylabel('Time')\n",
        "        ax.set_title(f'{param_name} Sensitivity')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        if i == 0: ax.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_dramatic_analysis()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jr\n",
        "import matplotlib.pyplot as plt\n",
        "import diffrax\n",
        "import time\n",
        "\n",
        "@jax.jit\n",
        "def calculate_time_to_collapse(ts, ys, threshold):\n",
        "    debris = ys[..., 1]\n",
        "    collapsed_mask = debris > threshold\n",
        "    collapse_times = jnp.where(collapsed_mask, ts, ts[-1] + 1.0)\n",
        "    first_collapse_time = jnp.min(collapse_times)\n",
        "    final_time = jnp.where(first_collapse_time > ts[-1], ts[-1], first_collapse_time)\n",
        "    return final_time\n",
        "\n",
        "def _get_data(ts, lambda_t_val, alpha, mu, k, beta, n0_value, *, key):\n",
        "    y0 = jnp.array([n0_value, n0_value / 2.0])\n",
        "\n",
        "    def lambda_t(t):\n",
        "        return lambda_t_val\n",
        "\n",
        "    def f(t, y, args):\n",
        "        return jnp.stack(\n",
        "            [lambda_t(t) - alpha * y[0] * y[1] - mu * y[0],\n",
        "             k * alpha * y[0] * y[1] - beta * y[1]], axis=-1)\n",
        "\n",
        "    solver = diffrax.Tsit5()\n",
        "    dt0 = 0.1\n",
        "    saveat = diffrax.SaveAt(ts=ts)\n",
        "\n",
        "    sol = diffrax.diffeqsolve(\n",
        "        diffrax.ODETerm(f),\n",
        "        solver,\n",
        "        ts[0],\n",
        "        ts[-1],\n",
        "        dt0,\n",
        "        y0,\n",
        "        saveat=saveat,\n",
        "        max_steps=50000\n",
        "    )\n",
        "    return sol.ys\n",
        "\n",
        "@jax.jit\n",
        "def single_simulation_and_analysis(lambda_val, n0_val, ts, alpha, mu, k, beta, collapse_threshold, key):\n",
        "    ys = _get_data(\n",
        "        ts=ts,\n",
        "        lambda_t_val=lambda_val,\n",
        "        alpha=alpha,\n",
        "        mu=mu,\n",
        "        k=k,\n",
        "        beta=beta,\n",
        "        n0_value=n0_val,\n",
        "        key=key\n",
        "    )\n",
        "    time_to_collapse = calculate_time_to_collapse(ts, ys, collapse_threshold)\n",
        "    return time_to_collapse\n",
        "\n",
        "def run_phase_analysis_vectorized(n0_values, lambda_values, ts, initial_params, collapse_threshold):\n",
        "    L_grid, N_grid = jnp.meshgrid(lambda_values, n0_values)\n",
        "    flat_L = L_grid.ravel()\n",
        "    flat_N = N_grid.ravel()\n",
        "    total_iterations = flat_L.size\n",
        "\n",
        "    p = initial_params\n",
        "    fixed_args = (ts, p['alpha'], p['mu'], p['k'], p['beta'], collapse_threshold)\n",
        "\n",
        "    analysis_key = jr.PRNGKey(420)\n",
        "    keys = jr.split(analysis_key, total_iterations)\n",
        "\n",
        "    print(f\"Starting 2D sweep with vmap (Total {total_iterations} iterations)...\")\n",
        "\n",
        "    vmapped_analysis = jax.vmap(single_simulation_and_analysis, in_axes=(0, 0, None, None, None, None, None, None, 0))\n",
        "    flat_results = vmapped_analysis(flat_L, flat_N, *fixed_args, keys)\n",
        "\n",
        "    results_matrix = flat_results.reshape(L_grid.shape)\n",
        "\n",
        "    return results_matrix.T\n",
        "\n",
        "def main_phase_diagram_analysis(seed=1234):\n",
        "    ts = jnp.linspace(0, 300, 100)\n",
        "    collapse_threshold = 15000\n",
        "\n",
        "    n0_values = jnp.linspace(10000, 40000, 15)\n",
        "    lambda_values = jnp.linspace(0, 5000, 20)\n",
        "\n",
        "    initial_params = {\n",
        "        'alpha': 4e-10,\n",
        "        'mu': 0.05,\n",
        "        'k': 2000.0,\n",
        "        'beta': 0.015,\n",
        "        'lambda_t_val': 1500,\n",
        "        'n0_value': 25000,\n",
        "    }\n",
        "\n",
        "    print(\"--- Starting Phase Diagram Analysis ---\")\n",
        "    print(f\"Max Simulation Time: {ts[-1]} hours\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    phase_results = run_phase_analysis_vectorized(\n",
        "        n0_values,\n",
        "        lambda_values,\n",
        "        ts,\n",
        "        initial_params,\n",
        "        collapse_threshold\n",
        "    )\n",
        "    end_time = time.time()\n",
        "    print(f\"Analysis completed in {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    img = plt.imshow(\n",
        "        phase_results,\n",
        "        aspect='auto',\n",
        "        origin='lower',\n",
        "        extent=[n0_values[0], n0_values[-1], lambda_values[0], lambda_values[-1]],\n",
        "        cmap='RdYlGn',\n",
        "        vmin=0,\n",
        "        vmax=ts[-1]\n",
        "    )\n",
        "\n",
        "    cbar = plt.colorbar(img)\n",
        "    cbar.set_label(f'Time to Collapse (Hours)', rotation=270, labelpad=20)\n",
        "\n",
        "    plt.xlabel(r'$N_0$')\n",
        "    plt.ylabel(r'$\\Lambda$')\n",
        "    plt.title(f'Kessler Syndrome Phase Diagram')\n",
        "\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_phase_diagram_analysis()"
      ],
      "metadata": {
        "id": "sT9Gusl7TROB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
